{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = pd.read_pickle('./data/pickle/preproc/df_patient_admit_icu_notes__20210206_singleICUSTAY_TRAIN_final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from customTransformers import (ColumnSelectTransformer, DiagnosisFrameTransformer, \n",
    "                                EstimatorTransformer, LinearNonlinear, ColumnMergeTransformer\n",
    "                               )\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['GENDER','ADMISSION_TYPE','ADMISSION_LOCATION','INSURANCE','LANGUAGE',\n",
    "       'RELIGION','MARITAL_STATUS','ETHNICITY']\n",
    "num_cols = ['ADMIT_AGE']\n",
    "\n",
    "demog_feats2 = FeatureUnion([\n",
    "    ('stdscl', ColumnTransformer([('numerical', StandardScaler(), num_cols)])),\n",
    "    ('ohe',  ColumnTransformer([('categorical', OneHotEncoder(handle_unknown='ignore'), cols)]))\n",
    "])\n",
    "demog_pipe2 = Pipeline([\n",
    "    ('features', demog_feats2),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "demog_params2 = {\n",
    "    'ridge__alpha': (0.01, 0.1, 1, 10, 100),\n",
    "    'ridge__normalize': ('uniform', 'distance'),\n",
    "    'ridge__fit_intercept': (True, False)\n",
    "}\n",
    "simp = SimpleImputer(strategy='median')\n",
    "y_train_imp = simp.fit(X_train[['LOS']]).transform(X_train[['LOS']])\n",
    "lin_gs_regressor2 = GridSearchCV(demog_pipe2, demog_params2, cv=KFold(n_splits=5, shuffle=True),verbose=3,n_jobs=-1)\n",
    "lin_est2 = lin_gs_regressor2.fit(X_train,y_train_imp)\n",
    "lin_est2.best_params_,lin_est2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagn_pipe2 = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(['DIAGNOSIS'])),\n",
    "    ('dst', DiagnosisFrameTransformer()),\n",
    "    ('count',CountVectorizer(max_features=3000)),\n",
    "    ('tfid', TfidfTransformer()),\n",
    "    ('rfr', RandomForestRegressor(n_estimators=50))\n",
    "])\n",
    "\n",
    "diagn_params2 = {\n",
    "    'rfr__criterion': ['mse','mae'],\n",
    "    'rfr__max_features': ['sqrt', 'log2'],\n",
    "    'rfr__min_samples_split': [0.2,0.225, 0.25],\n",
    "    'rfr__min_samples_leaf': [0.01, 0.02, 0.03],\n",
    "#     'rfr__ccp_alpha': [0,0.5,1],\n",
    "    'rfr__max_depth': [35, 40, 45, 50]\n",
    "}\n",
    "# y_train_imp.values.ravel() --> DataConversionWarning: A column-vector y was passed\n",
    "##                       when a 1d array was expected. Please change the shape of y to \n",
    "##                       (n_samples,), for example using ravel().\n",
    "diagn_gs_classifier2 = GridSearchCV(diagn_pipe2, diagn_params2, cv=KFold(n_splits=5, shuffle=True),verbose=3,n_jobs=12)\n",
    "tfidf_est2 = diagn_gs_classifier2.fit(X_train,y_train_imp.ravel())\n",
    "tfidf_est2.best_params_,tfidf_est2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear/nonlinear model fitting both simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['GENDER','ADMISSION_TYPE','ADMISSION_LOCATION','INSURANCE','LANGUAGE',\n",
    "       'RELIGION','MARITAL_STATUS','ETHNICITY']\n",
    "num_cols = ['ADMIT_AGE']\n",
    "\n",
    "count = CountVectorizer(max_features=3000)\n",
    "diagn_feats = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(['DIAGNOSIS'])),\n",
    "    ('dst', DiagnosisFrameTransformer()),\n",
    "    ('count',count),\n",
    "    ('tfid', TfidfTransformer()),\n",
    "])\n",
    "\n",
    "ohe = ColumnTransformer([('categorical', OneHotEncoder(handle_unknown='ignore'), cols)])\n",
    "all_feats = FeatureUnion([\n",
    "    ('stdscl', ColumnTransformer([('numerical', StandardScaler(), num_cols)])),\n",
    "    ('ohe',  ohe),\n",
    "    ('diagn', diagn_feats)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pipe_a = Pipeline([\n",
    "    ('features', all_feats),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "all_params3a = {\n",
    "    'ridge__alpha': (0.01, 0.1, 1, 10, 100),\n",
    "    'ridge__normalize': ('uniform', 'distance'),\n",
    "    'ridge__fit_intercept': (True, False)\n",
    "}\n",
    "simp = SimpleImputer(strategy='median')\n",
    "y_train_imp = simp.fit(X_train[['LOS']]).transform(X_train[['LOS']])\n",
    "lin_gs_regressor3 = GridSearchCV(all_pipe_a, all_params3a, cv=KFold(n_splits=5, shuffle=True),verbose=3,n_jobs=-1)\n",
    "lin_est3 = lin_gs_regressor3.fit(X_train,y_train_imp)\n",
    "lin_est3.best_params_,lin_est3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pipe_b = Pipeline([\n",
    "    ('features', all_feats),\n",
    "    ('rfr', RandomForestRegressor(n_estimators=75))\n",
    "])\n",
    "\n",
    "all_params3b = {\n",
    "    'rfr__criterion': ['mse','mae'],\n",
    "    'rfr__max_features': ['sqrt', 'log2'],\n",
    "    'rfr__min_samples_split': [0.2, 0.225, 0.25],\n",
    "    'rfr__min_samples_leaf': [0.0075, 0.01, 0.02, 0.03],\n",
    "    'rfr__ccp_alpha': [0, 0.5, 1],\n",
    "    'rfr__max_depth': [30, 35, 40, 45, 50, 55]\n",
    "}\n",
    "# simp = SimpleImputer(strategy='median')\n",
    "# y_train_imp = simp.fit(X_train[['LOS']]).transform(X_train[['LOS']])\n",
    "nl_gs_regressor3 = GridSearchCV(all_pipe_b, all_params3b, cv=KFold(n_splits=5, shuffle=True),verbose=3,n_jobs=6)\n",
    "nl_est3 = nl_gs_regressor3.fit(X_train,X_train[['LOS']])\n",
    "# nl_est3 = nl_gs_regressor3.fit(X_train,y_train_imp.ravel())\n",
    "nl_est3.best_params_,nl_est3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = Ridge(alpha=10,normalize ='uniform', fit_intercept=False)\n",
    "nonlinreg = RandomForestRegressor(n_estimators=75, criterion='mse',\n",
    "                                  max_depth=45,min_samples_leaf=0.0075,\n",
    "                                  min_samples_split=0.2, max_features = 'sqrt')\n",
    "regressor = LinearNonlinear(lin=linreg,nonlin=nonlinreg)\n",
    "l_nl_pipe = Pipeline([\n",
    "        ('features', all_feats), # features\n",
    "        ('regressor', regressor) # Ridge' + RandomForest\n",
    "    ])\n",
    "\n",
    "l_nl_est4 = l_nl_pipe.fit(X_train,X_train['LOS'].to_numpy().ravel())\n",
    "# l_nl_est4 = l_nl_pipe.fit(X_train,y_train_imp.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "/Users/adamgifford/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=7)]: Done  18 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=7)]: Done 114 tasks      | elapsed: 154.1min\n",
      "[Parallel(n_jobs=7)]: Done 274 tasks      | elapsed: 388.2min\n",
      "[Parallel(n_jobs=7)]: Done 480 out of 480 | elapsed: 737.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'features__text_feats__count__max_features': 10000,\n",
       "  'features__text_feats__count__min_df': 0.0001,\n",
       "  'features__text_feats__count__ngram_range': (1, 2),\n",
       "  'features__text_feats__tfid__norm': 'l2',\n",
       "  'reg__criterion': 'mse',\n",
       "  'reg__loss': 'ls'},\n",
       " 0.41783777928818394)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['GENDER','ADMISSION_TYPE','ADMISSION_LOCATION','INSURANCE','LANGUAGE',\n",
    "       'RELIGION','MARITAL_STATUS','ETHNICITY']\n",
    "num_cols = ['ADMIT_AGE']\n",
    "\n",
    "ohe = ColumnTransformer([('categorical', OneHotEncoder(handle_unknown='ignore'), cols)])\n",
    "demog_feats = FeatureUnion([\n",
    "    ('stdscl', ColumnTransformer([('numerical', StandardScaler(), num_cols)])),\n",
    "    ('ohe',  ohe)\n",
    "])\n",
    "\n",
    "text_feats = Pipeline([\n",
    "    ('dft', DiagnosisFrameTransformer(['DIAGNOSIS'])),\n",
    "    ('cmt', ColumnMergeTransformer(['DIAGNOSIS','TEXT'])),\n",
    "    ('cst', ColumnSelectTransformer('DIAGNOSIS_TEXT')),\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfid', TfidfTransformer())\n",
    "])\n",
    "\n",
    "feats_union = FeatureUnion([\n",
    "    ('demog_feats', demog_feats),\n",
    "    ('text_feats', text_feats)\n",
    "])\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    ('features', feats_union),\n",
    "    ('reg', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "reg_params = {\n",
    "    'features__text_feats__count__max_features': [2500, 5000, 10000],\n",
    "    'features__text_feats__count__min_df': [0.00001, 0.0001],\n",
    "    'features__text_feats__count__ngram_range': [(1,1),(1,2)],\n",
    "    'features__text_feats__tfid__norm': ['l1','l2'],\n",
    "    'reg__loss': ['ls','huber'],\n",
    "    'reg__criterion': ['mse','friedman_mse'],\n",
    "}\n",
    "\n",
    "lin_gs_classifier = GridSearchCV(reg_pipe, reg_params, cv=KFold(n_splits=5, shuffle=True),verbose=3,n_jobs=7)\n",
    "lin_est = lin_gs_classifier.fit(X_train,X_train['LOS'])\n",
    "\n",
    "lin_est.best_params_,lin_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for diagnoses + text columns\n",
    "file = './data/pickle/models/gradientboost__LOS__20210215.pkl'\n",
    "model_data = {\n",
    "    'numeric_cols': num_cols,\n",
    "    'categorical_cols': cols,\n",
    "    'diagnosis_col': ['DIAGNOSIS'],\n",
    "    'ohe_categoricals': ohe,\n",
    "    'feature_union': text_feats,\n",
    "    'gridsearch': lin_gs_classifier,\n",
    "    'estimator': lin_est\n",
    "}\n",
    "pickle.dump(model_data,open(file,'wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "previous best (2/15/2021)\n",
    "\n",
    "({'features__text_feats__count__max_features': 10000,\n",
    "  'features__text_feats__count__min_df': 0.0001,\n",
    "  'features__text_feats__count__ngram_range': (1, 2),\n",
    "  'features__text_feats__tfid__norm': 'l2',\n",
    "  'reg__criterion': 'mse',\n",
    "  'reg__loss': 'ls'},\n",
    " 0.41783777928818394)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './data/pickle/models/lin-nonlin__LOS__20210131.pkl'\n",
    "model_data = pickle.load(open(file,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['numeric_cols', 'categorical_cols', 'diagnosis_col', 'ohe_categoricals', 'feature_union', 'count_vectorizor', 'estimator'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = pd.read_pickle('./data/pickle/preproc/df_patient_admit_icu__20210130_singleICUSTAY_TEST_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 28\n",
    "\n",
    "foo = pd.DataFrame(X_test.iloc[ix]).T\n",
    "foo = foo.to_dict()\n",
    "bar = {key: val for key in foo for val in foo[key].values()}\n",
    "xx_test = pd.DataFrame(bar,index=[0])\n",
    "\n",
    "y_pred = model_data['estimator'].predict(xx_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.4874231435949032]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['LOS'].iloc[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
